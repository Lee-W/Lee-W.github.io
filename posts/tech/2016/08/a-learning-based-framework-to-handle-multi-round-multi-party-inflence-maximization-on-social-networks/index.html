<!DOCTYPE html>
<html lang="zh-tw">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Lee-W" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Paper, Social Network, Machine Learning, Game Theory, Tech, " />

<meta property="og:title" content="[Paper] A Learning-based Framework to Handle Multi-round Multi-party Influence Maximization on Social Networks "/>
<meta property="og:url" content="https://lee-w.github.io/posts/tech/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks" />
<meta property="og:description" content="Paper" />
<meta property="og:site_name" content="Laziness makes Great Engineer" />
<meta property="og:article:author" content="Lee-W" />
<meta property="og:article:published_time" content="2016-08-22T16:53:00+08:00" />
<meta name="twitter:title" content="[Paper] A Learning-based Framework to Handle Multi-round Multi-party Influence Maximization on Social Networks ">
<meta name="twitter:description" content="Paper">

        <title>[Paper] A Learning-based Framework to Handle Multi-round Multi-party Influence Maximization on Social Networks  Â· Laziness makes Great Engineer
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">

        <link rel="stylesheet" type="text/css" href="https://lee-w.github.io/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://lee-w.github.io/theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://lee-w.github.io/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://lee-w.github.io/theme/css/admonition.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://lee-w.github.io/theme/css/custom.css" media="screen">
        <link href="https://lee-w.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Laziness makes Great Engineer - Full Atom Feed" />
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-96190677-1', 'auto');
    ga('send', 'pageview');
</script>



    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container-fluid">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="https://lee-w.github.io/"><span class=site-name>Laziness makes Great Engineer</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="https://lee-w.github.io">Home</a></li>
                            <li ><a href="https://lee-w.github.io/pages/about-me.html">About Me</a></li>
                            <li ><a href="https://lee-w.github.io/pages/about-this-blog.html">About This Blog</a></li>
                            <li ><a href="https://lee-w.github.io/categories">Categories</a></li>
                            <li ><a href="https://lee-w.github.io/tags">Tags</a></li>
                            <li ><a href="https://lee-w.github.io/archives">Archives</a></li>
                            <li><form class="navbar-search" action="https://lee-w.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
    <h1><a href="https://lee-w.github.io/posts/tech/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks"> [Paper] A Learning-based Framework to Handle Multi-round Multi-party Influence Maximization on Social Networks  </a></h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">

            
            <p><a href="http://dl.acm.org/citation.cfm?id=2783392">Paper</a></p>
<!--more-->

<h2 id="1-introduction">1. Introduction</h2>
<ul>
<li>
<p>Problem Description</p>
<ul>
<li>A company intends to select a small set of customers to distribute praises of their trial products to a larger group</li>
</ul>
</li>
<li>
<p>Influence maximization</p>
<ul>
<li>Goal: Identify a small subset of seed nodes that have the best chance to influence the most number of nodes</li>
<li>Competitive Influence Maximization (CIM)</li>
</ul>
</li>
<li>
<p>Assumption</p>
<ul>
<li>Influence is exclusive (Once a node is influenced by one party, it will not be influenced again)      </li>
<li>Each round all parties choose one node and then the influence propagates before the next round starts</li>
</ul>
</li>
<li>
<p>STORM (STrategy-Oriented Reinforcement-Learning based influence Maximization) performs</p>
<ul>
<li>Data Generation<ul>
<li>the data, which is the experience generated through simulation by applying the current model, will become the feedbacks to refine the model for better performance </li>
</ul>
</li>
<li>Model Learning </li>
</ul>
</li>
</ul>
<h3 id="difference-with-others">Difference with Others</h3>
<ol>
<li>Known strategy -&gt; Both know and unknown<ul>
<li>Known or Unknown but available to compete -&gt; Train a model to learn strategy</li>
<li>Unknown -&gt; Game-theoretical solution to seek the Nash equilibrium     </li>
</ul>
</li>
<li>Single-roung -&gt; Multi-round</li>
<li>Model driven -&gt; learning-based, data-drivern</li>
<li>Not considering different network topology -&gt; General to adapt both opponent's strategy and environment setting (e.g. underlying network topology)</li>
</ol>
<h2 id="2-problem-statment">2. Problem Statment</h2>
<h3 id="def-1-competive-linear-threshold-clt">Def 1: Competive Linear Threshold (CLT)</h3>
<ul>
<li>CLT model is a multi-party diffusion model</li>
<li>The party who has the highest influence occupied the node</li>
</ul>
<h3 id="def-2-multi-round-competitive-influence-maximization-mrcim">Def 2: Multi-Round Competitive Influence Maximization (MRCIM)</h3>
<ul>
<li>Max its overall relative influence</li>
</ul>
<h2 id="4-methodology">4. Methodology</h2>
<ul>
<li>NP-hardness of MRCIM -&gt; looks for approxmiate solution</li>
<li>Max the inflence for each round does not guarantee overall max<ul>
<li>Due to the fact that each round are not independent</li>
</ul>
</li>
</ul>
<h3 id="41-preliminary-reinforcement-learning">4.1 Preliminary: Reinforcement Learning</h3>
<ul>
<li>Learn a policy <span class="math">\(\pi(s)\)</span> to determine which action to take state s (environment)</li>
<li>How to estimated <span class="math">\(\pi\)</span>?<ul>
<li>Expected Accmulated Reward of a state (V function)<ul>
<li><span class="math">\( V^\pi(s) = E_\pi\{R_t|S_t=s\}=...\)</span></li>
</ul>
</li>
<li>Expected Accmulated Reward of a state-action pair (Q function)<ul>
<li><span class="math">\( Q^\pi(s, a) = E_\pi\{R_t|S_t=s, a_t=a\}=...\)</span></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The optimal <span class="math">\(\pi\)</span> can be obtained through Q functinon</p>
<p><span class="math">\( \pi = \arg \min_{a\in A}Q(s,a)\)</span></p>
<p>(i.e. For all "a" in A, find the "a" such that min Q(s, a))</p>
<h3 id="42-strategy-oriented-reinforcement-learning">4.2 Strategy-Oriented Reinforcement-Learning</h3>
<h4 id="setup">Setup</h4>
<ul>
<li>Env<ul>
<li>Influence propagation process</li>
</ul>
</li>
<li>Reward<ul>
<li>Delay Reward: The difference of activated nodes between parties at the last round<ul>
<li>After the last round, rewards are propagated to the previous states through Q-function updating</li>
<li>Slow but more accurate</li>
</ul>
</li>
</ul>
</li>
<li>Action<ul>
<li><s>Choosing certain node to activate</s><ul>
<li>too many</li>
<li>overfit</li>
</ul>
</li>
<li>Single Party IM strategies<ul>
<li>Namely, which strategy to choose given the current state</li>
<li>The size can be reduced to strategies choosen</li>
<li>Chosen Strategies<ul>
<li>sub-greedy</li>
<li>degree-first</li>
<li>block</li>
<li>max-weight</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>State<ul>
<li>Represents<ul>
<li>network</li>
<li>environment status</li>
</ul>
</li>
<li><s>record the occupation status of all nodes</s><ul>
<li><span class="math">\(3^{|V|}\)</span>, too many</li>
<li>overfit</li>
</ul>
</li>
<li>Features Designed<ul>
<li>Number of free nodes</li>
<li>Sum of degrees of all nodes</li>
<li>Sum of weight of the edges for which bot h vertices are free</li>
<li>Max degree among all free nodes</li>
<li>Max sum of free out-edge weight of a node among nodes which are the first player's neighbors</li>
<li>Second player's </li>
<li>Max activated nodes of a node for the first player alter two rounds of influence propagation</li>
<li>Second player's</li>
</ul>
</li>
<li>The feautres are quantize into<ul>
<li>low</li>
<li>medium</li>
<li>high</li>
</ul>
</li>
<li>Totally, <span class="math">\(3^9\)</span> states</li>
</ul>
</li>
</ul>
<h4 id="data-for-training">Data For Training</h4>
<ul>
<li>Propagation model is known (e.g. LT in the experiments)</li>
<li>Strategies served as actions are predefined</li>
</ul>
<p>In training phase, train the agent aginst a certain strategy and see how it performs on the given network<br>
These data can be used to learn the value functions</p>
<h4 id="training-against-opponents">Training Against Opponents</h4>
<ul>
<li>Opponent Strategy<ul>
<li>Known: Simulate the strategy during training</li>
<li>Unknown but availble during training: Same as above</li>
<li>Unknown: More Gerneral Model in 4.4</li>
</ul>
</li>
</ul>
<h4 id="phase">Phase</h4>
<ul>
<li>Phase 1: Training<ul>
<li>The agent update its Q function from the simulation experiences throughout the training rounds</li>
<li>Update <span class="math">\(\pi\)</span> in the meantime</li>
</ul>
</li>
<li>Phase 2: Competition<ul>
<li>The agent would not update Q-table</li>
<li>Generates <span class="math">\(\pi\)</span> according to Q-table</li>
</ul>
</li>
</ul>
<h2 id="43-storm-with-strategy-known">4.3 STORM with Strategy Known</h2>
<ul>
<li>Training the model compete against the strategy to learn <span class="math">\(\pi\)</span></li>
<li>STORM-Q<ul>
<li>Update Q-function following the concept of Q-learning<ul>
<li>Q-Learning: <span class="math">\(Q(S_t, a_t) = Q(S_t, a_t) + \alpha * (r_{t+1} + \gamma * max_{a}Q(S_{t+1}, a) -Q(S_t, a_t))\)</span></li>
</ul>
</li>
<li><span class="math">\(\epsilon\)</span>-greedy<ul>
<li>Determine strategies on the current policy derived from Q-table.</li>
<li>Explore the new directions to avoid local optimum</li>
</ul>
</li>
<li>Pure Strategy</li>
<li>The most likely strategy is choosen</li>
</ul>
</li>
</ul>
<p>$ Algorithm $</p>
<h2 id="44-storm-with-strategy-unknown">4.4 STORM with Strategy Unknown</h2>
<h3 id="unknown-but-available-to-train">Unknown but available to train</h3>
<ul>
<li>The differece between the known case is that experience cannot be obtained through simulation</li>
<li>Train against unknown opponent's strategy during competition<ul>
<li>It's feasible because STORM-Q only needs to know the seed-selection outcoms of the opponent to update the Q-table, not exact strategy it takes</li>
</ul>
</li>
</ul>
<h3 id="unknown">Unknown</h3>
<ul>
<li>Goal: Create a general model to compete a variety of rational strategies</li>
<li>Assumption: The oppoent is rational (Wants to max influence and knows its oppoent wants so)</li>
<li>STORM-QQ<ul>
<li>Two STROM-Q compete and update Q-tabale at the same time</li>
<li>Using current Q-table during training phase</li>
<li>Pure Strategy<ul>
<li>Does Not guarantee that equilibrium exists in MRCIM</li>
</ul>
</li>
</ul>
</li>
<li>
<p>STORM-MM</p>
<ul>
<li>Mix Strategy (Samples an action from the distribution of actions in each state)</li>
<li>In two-player zero-sum game<ul>
<li>Nash equilibrium is graranteed to exist with miexed strategies</li>
<li>Use MINMAX theorem to find the equilibrium</li>
</ul>
</li>
<li><span class="math">\(Q(s, a, o)\)</span>: The reward of first party when using strategy <span class="math">\(a\)</span> against oppoent's strategy <span class="math">\(o\)</span> in state <span class="math">\(s\)</span></li>
<li><span class="math">\(Q_{t+1}(s_t, a_t, o_t) = (1-\alpha)Q_t(s_t, a_t, o_t)+\alpha[r_{t+1}+\gamma V(s_{t+1})]\)</span></li>
<li>Operations  Research</li>
</ul>
</li>
<li>
<p>The differece between STROM-QQ and STORM-MM</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>STROM-QQ</th>
<th>STROM-MM</th>
</tr>
</thead>
<tbody>
<tr>
<td>Max the reward in their own Q-table</td>
<td>Finds equilibrium with one Q-table and determines both side's <span class="math">\(a\)</span> at the same time</td>
</tr>
<tr>
<td>Pure Strategies</td>
<td>Mixed Strategies</td>
</tr>
<tr>
<td>Choose strategy by greedy</td>
<td>Samples from the mixed strategy <span class="math">\(\pi_a\)</span> or <span class="math">\(\pi_o\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li>Ideally, they should have simliar result in two-party MRCIM. In practice, the result might not due to<ul>
<li>STORM-QQ does not guarantee equilibrium</li>
<li>Although equilibrium exists in STORM-MM. It does not guarantee to be found due to lack of training data or bad init or such problems.</li>
</ul>
</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            <div>
</div>

            <section>
    <p id="post-share-links">
    Share on:
    <a href="https://twitter.com/intent/tweet?text=%5BPaper%5D%20A%20Learning-based%20Framework%20to%20Handle%20Multi-round%20Multi-party%20Influence%20Maximization%20on%20Social%20Networks&url=https%3A//lee-w.github.io/posts/tech/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks&hashtags=paper,social-network,machine-learning,game-theory" target="_blank" title="Share on Twitter">Twitter</a>
    â
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//lee-w.github.io/posts/tech/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks" target="_blank" title="Share on Facebook">Facebook</a>
    â
    <a href="mailto:?subject=%5BPaper%5D%20A%20Learning-based%20Framework%20to%20Handle%20Multi-round%20Multi-party%20Influence%20Maximization%20on%20Social%20Networks&amp;body=https%3A//lee-w.github.io/posts/tech/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks" target="_blank" title="Share via Email">Email</a>
    </p>
</section>

            <section>
<div class="accordion" id="accordion2">
    <div class="accordion-group">
        <div class="accordion-heading">
            <a class="accordion-toggle disqus-comment-count" data-toggle="collapse" data-parent="#accordion2"
                href="https://lee-w.github.io/posts/tech/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks#disqus_thread",
                id="disqus-accordion-toggle">
                Comments
            </a>
        </div>
        <div id="disqus_thread" class="accordion-body collapse">
            <div class="accordion-inner">
                <div class="comments">
                    <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'lee-w-blog';
        var disqus_identifier = 'https://lee-w.github.io/posts/tech/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks';
    var disqus_url = 'https://lee-w.github.io/posts/tech/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks';

    (function() {
         var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
         dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
         (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
</script>
<noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

                </div>
            </div>
        </div>
    </div>
</div>
</section>

            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">Â« <a href="https://lee-w.github.io/posts/tech/2016/08/coscup-2016" title="Previous: COSCUP 2016">COSCUP 2016</a></li>
                <li class="next-article"><a href="https://lee-w.github.io/posts/book/2016/08/how-will-you-measure-your-life" title="Next: [Book] ä½ å¦ä½è¡¡éä½ çäººç">[Book] ä½ å¦ä½è¡¡éä½ çäººç</a> Â»</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
    <h4>Reading Time</h4>
    <p>~5 min read</p>
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2016-08-22T16:53:00+08:00">2016/08/22 - ä¸</time>
                <h4>Read Time</h4>
                 5 min
            <h4>Category</h4>
            <a class="category-link" href="https://lee-w.github.io/categories.html#tech-ref">Tech</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://lee-w.github.io/tags#game-theory-ref">Game Theory
                    <span>2</span>
</a></li>
                <li><a href="https://lee-w.github.io/tags#machine-learning-ref">Machine Learning
                    <span>5</span>
</a></li>
                <li><a href="https://lee-w.github.io/tags#paper-ref">Paper
                    <span>5</span>
</a></li>
                <li><a href="https://lee-w.github.io/tags#social-network-ref">Social Network
                    <span>2</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="https://tw.linkedin.com/in/clleew" title="My Linkedin Profile" class="sidebar-social-links" target="_blank">
            <i class="fab fa-linkedin sidebar-social-links"></i>
    </a>
    <a href="https://github.com/Lee-W" title="My GitHub Profile" class="sidebar-social-links" target="_blank">
            <i class="fab fa-github sidebar-social-links"></i>
    </a>
    <a href="https://gitlab.com/Lee-W" title="My Gitlab Profile" class="sidebar-social-links" target="_blank">
            <i class="fab fa-gitlab sidebar-social-links"></i>
    </a>
    <a href="https://twitter.com/clleew" title="My Twitter Profile" class="sidebar-social-links" target="_blank">
            <i class="fab fa-twitter sidebar-social-links"></i>
    </a>
    <a href="//lee-w.github.io/feeds/all.atom.xml" title="Subscribe in a reader" class="sidebar-social-links" target="_blank">
            <i class="fas fa-rss sidebar-social-links"></i>
    </a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="https://github.com/Pelican-Elegant/elegant/" title="Theme Elegant Home Page">Elegant</a></li>
    </ul>
</div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

            <script type="text/javascript">
var disqus_shortname = 'lee-w-blog';
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>
<script  language="javascript" type="text/javascript">
function uncollapse() {
    if (window.location.hash.match(/^#comment-\d+$/)) {
        $('#disqus_thread').collapse('show');
    }
}
</script>
<script type="text/javascript" language="JavaScript">
uncollapse();
window.onhashchange=function(){
    if (window.location.hash.match(/^#comment-\d+$/))
        window.location.reload(true);
}
</script>
<script>
$('#disqus_thread').on('shown', function () {
    var link = document.getElementById('disqus-accordion-toggle');
    var old_innerHTML = link.innerHTML;
    $(link).fadeOut(500, function() {
        $(this).text('Click here to hide comments').fadeIn(500);
    });
    $('#disqus_thread').on('hidden', function () {
        $(link).fadeOut(500, function() {
            $(this).text(old_innerHTML).fadeIn(500);
        });
    })
})
</script>


    </body>
    <!-- Theme: Elegant built for Pelican
    License : MIT -->
</html>